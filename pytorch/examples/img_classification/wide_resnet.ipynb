{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "Tutorial from https://hackernoon.com/training-an-image-classifier-from-scratch-in-15-minutes-3c140f5fa1af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/N/u/sekanaya/anaconda3/envs/pynet/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/N/u/sekanaya/anaconda3/envs/pynet/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/N/u/sekanaya/anaconda3/envs/pynet/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as tt\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from fastai.dataset import ModelData\n",
    "from fastai.conv_learner import ConvLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(bs, num_workers):\n",
    "    PATH = \"/N/u/sekanaya/sali/git/github/esaliya/python/data/cifar10/\"\n",
    "    trn_dir, val_dir = PATH + 'train', PATH + 'test'\n",
    "    stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "    \n",
    "    # Data transforms (normalization & data augmentation)\n",
    "    tfms = [tt.ToTensor(), tt.Normalize(*stats)]\n",
    "    aug_tfms = tt.Compose([tt.RandomCrop(32, padding=4), \n",
    "                           tt.RandomHorizontalFlip()] + tfms)\n",
    "    # PyTorch datasets\n",
    "    trn_ds = ImageFolder(trn_dir, aug_tfms)\n",
    "    val_ds = ImageFolder(val_dir, tt.Compose(tfms))\n",
    "    aug_ds = ImageFolder(val_dir, aug_tfms)\n",
    "    \n",
    "    # PyTorch data loaders\n",
    "    trn_dl = DataLoader(trn_ds, batch_size=bs, shuffle=True, \n",
    "                        num_workers=num_workers, pin_memory=True)\n",
    "    val_dl = DataLoader(val_ds, batch_size=bs, shuffle=False, \n",
    "                        num_workers=num_workers, pin_memory=True)\n",
    "    aug_dl = DataLoader(aug_ds, batch_size=bs, shuffle=False, \n",
    "                        num_workers=num_workers, pin_memory=True)\n",
    "    \n",
    "    # FastAI model data \n",
    "    data = ModelData(PATH, trn_dl, val_dl)\n",
    "    data.aug_dl = aug_dl\n",
    "    data.sz = 32\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learner(arch, bs):\n",
    "    \"\"\"Create a FastAI learner using the given model\"\"\"\n",
    "    data = get_data(bs, 24)\n",
    "    learn = ConvLearner.from_model_data(arch.cuda(), data)\n",
    "    learn.crit = nn.CrossEntropyLoss()\n",
    "#     learn.metrics = [\"accuracy\"]\n",
    "    return learn\n",
    "\n",
    "def get_TTA_accuracy(learn):\n",
    "    \"\"\"Calculate accuracy with Test Time Agumentation(TTA)\"\"\"\n",
    "    preds, targs = learn.TTA()\n",
    "    preds = 0.6 * preds[0] + 0.4 * preds[1:].sum(0)\n",
    "    return accuracy_np(preds, targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def conv_2d(ni, nf, stride=1, ks=3):\n",
    "    \"\"\"3x3 convolution with 1 pixel padding\"\"\"\n",
    "    return nn.Conv2d(in_channels=ni, out_channels=nf, \n",
    "                     kernel_size=ks, stride=stride, \n",
    "                     padding=ks//2, bias=False)\n",
    "\n",
    "def bn_relu_conv(ni, nf):\n",
    "    \"\"\"BatchNorm → ReLU → Conv2D\"\"\"\n",
    "    return nn.Sequential(nn.BatchNorm2d(ni), \n",
    "                         nn.ReLU(inplace=True), \n",
    "                         conv_2d(ni, nf))\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"Residual block with shortcut connection\"\"\"\n",
    "    def __init__(self, ni, nf, stride=1):\n",
    "        super().__init__()\n",
    "        self.bn = nn.BatchNorm2d(ni)\n",
    "        self.conv1 = conv_2d(ni, nf, stride)\n",
    "        self.conv2 = bn_relu_conv(nf, nf)\n",
    "        self.shortcut = lambda x: x\n",
    "        if ni != nf:\n",
    "            self.shortcut = conv_2d(ni, nf, stride, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn(x), inplace=True)\n",
    "        r = self.shortcut(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x) * 0.2\n",
    "        return x.add_(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_group(N, ni, nf, stride):\n",
    "    \"\"\"Group of residual blocks\"\"\"\n",
    "    start = BasicBlock(ni, nf, stride)\n",
    "    rest = [BasicBlock(nf, nf) for j in range(1, N)]\n",
    "    return [start] + rest\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self): super().__init__()\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "class WideResNet(nn.Module):\n",
    "    def __init__(self, n_groups, N, n_classes, k=1, n_start=16):\n",
    "        super().__init__()      \n",
    "        # Increase channels to n_start using conv layer\n",
    "        layers = [conv_2d(3, n_start)]\n",
    "        n_channels = [n_start]\n",
    "        \n",
    "        # Add groups of BasicBlock(increase channels & downsample)\n",
    "        for i in range(n_groups):\n",
    "            n_channels.append(n_start*(2**i)*k)\n",
    "            stride = 2 if i>0 else 1\n",
    "            layers += make_group(N, n_channels[i], \n",
    "                                 n_channels[i+1], stride)\n",
    "        \n",
    "        # Pool, flatten & add linear layer for classification\n",
    "        layers += [nn.BatchNorm2d(n_channels[3]), \n",
    "                   nn.ReLU(inplace=True), \n",
    "                   nn.AdaptiveAvgPool2d(1), \n",
    "                   Flatten(), \n",
    "                   nn.Linear(n_channels[3], n_classes)]\n",
    "        \n",
    "        self.features = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x): return self.features(x)\n",
    "    \n",
    "def wrn_22(): \n",
    "    return WideResNet(n_groups=3, N=3, n_classes=10, k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.38 s, sys: 668 ms, total: 3.04 s\n",
      "Wall time: 3.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn = get_learner(wrn_22(), 128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2b133a0b42146a0a7f157653898d259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=20), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.276207   1.528313  \n",
      "    1      0.976014   1.166423                               \n",
      "    2      0.81544    0.991873                               \n",
      "    3      0.70645    0.96148                                \n",
      "    4      0.65028    0.783206                               \n",
      "    5      0.633292   1.216715                               \n",
      "    6      0.615304   1.043887                               \n",
      "    7      0.610193   1.211688                               \n",
      "    8      0.608913   1.132347                               \n",
      "    9      0.56096    0.751941                               \n",
      "    10     0.553828   1.025181                               \n",
      "    11     0.534848   0.898866                               \n",
      "    12     0.512698   1.01549                                \n",
      "    13     0.485222   0.712462                               \n",
      "    14     0.43034    0.620588                               \n",
      "    15     0.391012   0.579668                               \n",
      "    16     0.309446   0.319198                               \n",
      "    17     0.245132   0.303127                               \n",
      "    18     0.198602   0.26048                                \n",
      "    19     0.145073   0.226401                               \n",
      "\n",
      "CPU times: user 1h 57min 13s, sys: 20min 14s, total: 2h 17min 27s\n",
      "Wall time: 2h 18min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn.clip = 1e-1\n",
    "learn.fit(1.5, 1, wds=1e-4, cycle_len=20, use_clr_beta=(12, 15, 0.95, 0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5457c6e8f82d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_TTA_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-0d8286089435>\u001b[0m in \u001b[0;36mget_TTA_accuracy\u001b[0;34m(learn)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTTA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.6\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy_np' is not defined"
     ]
    }
   ],
   "source": [
    "get_TTA_accuracy(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
